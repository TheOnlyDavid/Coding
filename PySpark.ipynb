{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37873671-d5e9-4160-aa13-1c93f0719d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1\n",
    "Reading CSV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aadc484c-5a84-47d0-aada-8ffa5e1df51c",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee6c555-6597-43ea-84c5-568979fec727",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9eeac20-4c8d-45f6-99f6-867341257795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.68.110:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb0c1a0a2e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4ac3c2-4703-405c-82f3-c6a424bcb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/aaron/Downloads/Ex_Files_Spark_SQL_DataFrames/Exercise Files/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51265c7-7a9c-43df-93bc-62f143f1669b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path = data_path + '/location_temp.csv'\n",
    "df1 = spark.read.format('csv').option('header','true').load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bac1886a-42e1-4176-8445-036ea7fabee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(event_date='03/04/2019 19:48:06', location_id='loc0', temp_celcius='29'),\n",
       " Row(event_date='03/04/2019 19:53:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 19:58:06', location_id='loc0', temp_celcius='28'),\n",
       " Row(event_date='03/04/2019 20:03:06', location_id='loc0', temp_celcius='30'),\n",
       " Row(event_date='03/04/2019 20:08:06', location_id='loc0', temp_celcius='27')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ec921d-b083-456b-a774-1c619b364780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7571c7f-f6b0-44ce-84e6-97992cca064e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9ee954-541c-42fd-b648-6e41fb881b3a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flie_path_no_header = data_path + '/utilization.csv'\n",
    "df2 = spark.read.format('csv').option('header','false').option('inferSchema','true').load(flie_path_no_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f7a2401-1137-4005-be7d-24f7a70108a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d313005-0703-4197-9299-98e060fdceb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='03/05/2019 08:06:14', _c1=100, _c2=0.57, _c3=0.51, _c4=47),\n",
       " Row(_c0='03/05/2019 08:11:14', _c1=100, _c2=0.47, _c3=0.62, _c4=43),\n",
       " Row(_c0='03/05/2019 08:16:14', _c1=100, _c2=0.56, _c3=0.57, _c4=62),\n",
       " Row(_c0='03/05/2019 08:21:14', _c1=100, _c2=0.57, _c3=0.56, _c4=50),\n",
       " Row(_c0='03/05/2019 08:26:14', _c1=100, _c2=0.35, _c3=0.46, _c4=43),\n",
       " Row(_c0='03/05/2019 08:31:14', _c1=100, _c2=0.41, _c3=0.58, _c4=48),\n",
       " Row(_c0='03/05/2019 08:36:14', _c1=100, _c2=0.57, _c3=0.35, _c4=58),\n",
       " Row(_c0='03/05/2019 08:41:14', _c1=100, _c2=0.41, _c3=0.4, _c4=58),\n",
       " Row(_c0='03/05/2019 08:46:14', _c1=100, _c2=0.53, _c3=0.35, _c4=62),\n",
       " Row(_c0='03/05/2019 08:51:14', _c1=100, _c2=0.51, _c3=0.6, _c4=45)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0dc0631-e4e0-4e60-980f-507cb6cf1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed('_c0','event_datetime') \\\n",
    "         .withColumnRenamed('_c1','server_id') \\\n",
    "         .withColumnRenamed('_c2','cpu_utilization') \\\n",
    "         .withColumnRenamed('_c3','free_memory') \\\n",
    "         .withColumnRenamed('_c4','session_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4072ac72-51b0-4b1f-8f68-a2247b3bf1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ce38d-3aeb-44e6-8507-2812cd8a1aa4",
   "metadata": {},
   "source": [
    "## 2\n",
    "JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "300ab2c7-e624-4fbc-80c5-2c944df58f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20371293-6e4f-4062-b45d-45e8a97b27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92c562f6-1749-4c98-88db-54743c64f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/aaron/Downloads/Ex_Files_Spark_SQL_DataFrames/Exercise Files/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b583ba63-578c-46eb-b56f-9b3a50b792d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "json_df1_path = data_path + '/utlization.json'\n",
    "df1 = spark.read.format('json').load(json_df1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d88df22-ed96-41b5-bed8-8458ac1f57eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "523ce3f6-168f-4169-87b5-95c06ce4482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0710a61-a122-4d55-8ce2-21c53a6924e8",
   "metadata": {},
   "source": [
    "## 3\n",
    "Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc8df832-f1d4-4caf-9e4f-b8b4f0d59b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu_utilization',\n",
       " 'event_datetime',\n",
       " 'free_memory',\n",
       " 'server_id',\n",
       " 'session_count']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3277c34c-f830-418d-873f-da0dcb910546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sample = df1.sample(False, fraction = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2db59153-b360-48ce-b6ac-36c1d7e6dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.61|03/05/2019 09:51:14|       0.34|      100|           70|\n",
      "|           0.44|03/05/2019 09:56:14|       0.48|      100|           63|\n",
      "|           0.57|03/05/2019 10:46:14|       0.46|      100|           50|\n",
      "|           0.44|03/05/2019 11:16:14|       0.47|      100|           43|\n",
      "|           0.65|03/05/2019 12:21:14|       0.37|      100|           65|\n",
      "|           0.58|03/05/2019 12:51:14|       0.49|      100|           42|\n",
      "|           0.39|03/05/2019 15:01:14|       0.52|      100|           48|\n",
      "|           0.34|03/05/2019 15:41:14|       0.46|      100|           62|\n",
      "|           0.63|03/05/2019 15:51:14|       0.66|      100|           44|\n",
      "|           0.29|03/05/2019 16:21:14|       0.53|      100|           43|\n",
      "|           0.66|03/05/2019 16:51:14|       0.35|      100|           64|\n",
      "|           0.35|03/05/2019 17:06:14|       0.66|      100|           44|\n",
      "|           0.34|03/05/2019 17:26:14|       0.61|      100|           52|\n",
      "|            0.3|03/05/2019 17:31:14|       0.67|      100|           41|\n",
      "|           0.39|03/05/2019 19:26:14|       0.47|      100|           67|\n",
      "|           0.55|03/05/2019 23:06:14|       0.33|      100|           66|\n",
      "|           0.35|03/05/2019 23:21:14|       0.64|      100|           38|\n",
      "|           0.29|03/06/2019 00:06:14|        0.6|      100|           63|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2899ae5-b002-48eb-94eb-8df583d1575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.86|03/05/2019 08:06:16|       0.09|      101|           93|\n",
      "|           0.61|03/05/2019 08:06:17|       0.12|      102|           71|\n",
      "|           0.64|03/05/2019 08:06:19|       0.32|      103|           96|\n",
      "|           0.84|03/05/2019 08:06:21|       0.36|      104|           94|\n",
      "|           0.54|03/05/2019 08:06:23|       0.38|      105|           74|\n",
      "|            0.4|03/05/2019 08:06:24|       0.39|      106|           43|\n",
      "|           0.64|03/05/2019 08:06:26|       0.55|      107|           56|\n",
      "|           0.62|03/05/2019 08:06:28|       0.41|      108|           86|\n",
      "|            0.7|03/05/2019 08:06:29|       0.59|      109|           77|\n",
      "|           0.68|03/05/2019 08:06:31|       0.44|      110|           47|\n",
      "|           0.48|03/05/2019 08:06:33|       0.25|      111|           70|\n",
      "|           0.71|03/05/2019 08:06:34|       0.27|      112|           86|\n",
      "|           0.69|03/05/2019 08:06:36|       0.38|      113|           71|\n",
      "|           0.48|03/05/2019 08:06:38|       0.48|      114|           52|\n",
      "|           0.78|03/05/2019 08:06:40|       0.22|      115|           62|\n",
      "|            0.4|03/05/2019 08:06:41|       0.53|      116|           51|\n",
      "|           0.71|03/05/2019 08:06:43|       0.61|      117|           60|\n",
      "|           0.78|03/05/2019 08:06:45|       0.45|      118|           68|\n",
      "|           0.51|03/05/2019 08:06:46|       0.49|      119|           53|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1_sort = df1.sort('event_datetime')\n",
    "df1_sort.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca8e1e-b292-4e40-b968-7cb00338c906",
   "metadata": {},
   "source": [
    "## 4\n",
    "DF API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77b74c07-4512-4071-999d-bb6f3f3c872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_path + '/location_temp.csv'\n",
    "df1 = spark.read.format('csv').option('header','true').load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28638ca8-111f-4963-a86e-433e059a48bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d1026da-612b-43e9-b922-b3b7a1cba278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1['location_id'] == 'loc0').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aad9747a-f867-47ed-9991-62723c17378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1['location_id'] == 'loc0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d68eb730-266f-48b7-ab56-342af849d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1['location_id'] == 'loc5').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf234d-c9e4-445b-a6c6-518958ebfb18",
   "metadata": {},
   "source": [
    "## 5\n",
    "Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e487e133-7f94-481b-b113-3ca8b8027dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|      loc22| 1000|\n",
      "|      loc31| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1883832d-0c47-457c-9b0a-550a822782de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.orderBy('location_id').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4944c07-8a9f-47f5-ac07-de08e267be1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|      loc22|           28.251|\n",
      "|      loc31|           25.196|\n",
      "|      loc82|           27.355|\n",
      "|      loc90|           23.216|\n",
      "|     loc118|           24.219|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').agg({'temp_celcius' : 'mean'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2458abdc-f2d2-435e-9ba8-e73750aefc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|max(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|       loc0|               36|\n",
      "|       loc1|               35|\n",
      "|      loc10|               32|\n",
      "|     loc100|               34|\n",
      "|     loc101|               32|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').agg({'temp_celcius' : 'max'}).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d02778-06ee-4438-8128-38be5c8c938c",
   "metadata": {},
   "source": [
    "## 6 \n",
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73e18294-22d4-48a5-981c-2cd1c4766b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16bbeaf3-1e8f-4e69-9e8a-48ed15550be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50288"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_s1 = df1.sample(fraction = 0.1, withReplacement = False)\n",
    "df1_s1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46dd7434-dcab-48ad-a768-3d9993f47140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|      loc22|             28.46|\n",
      "|      loc31| 25.63716814159292|\n",
      "|      loc82|          27.46875|\n",
      "|      loc90|22.935185185185187|\n",
      "|     loc118|23.855855855855857|\n",
      "+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1_s1.groupBy('location_id').agg({'temp_celcius' : 'mean'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ac9ffdf-7527-4a25-99c1-db76a745bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|       loc0|29.216216216216218|\n",
      "|       loc1|28.263636363636362|\n",
      "|      loc10| 25.11111111111111|\n",
      "|     loc100| 27.22772277227723|\n",
      "|     loc101| 25.57843137254902|\n",
      "+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_s1.groupBy('location_id').agg({'temp_celcius' : 'mean'}).orderBy('location_id').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c38d1d37-78aa-4704-b19b-25631eff9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|       loc0|           29.176|\n",
      "|       loc1|           28.246|\n",
      "|      loc10|           25.337|\n",
      "|     loc100|           27.297|\n",
      "|     loc101|           25.317|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('location_id').agg({'temp_celcius' : 'mean'}).orderBy('location_id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c34d8-ea00-4d53-9a70-0114a12cdd91",
   "metadata": {},
   "source": [
    "## 7\n",
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61373f99-acd8-4294-923f-1ec2fb7ff59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.write.csv('df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3361c203-b099-478f-8b6f-5274f70729a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\n",
      "part-00000-38ebd5a2-ff1b-42a4-aa48-437af9b7ff38-c000.csv\n",
      "part-00001-38ebd5a2-ff1b-42a4-aa48-437af9b7ff38-c000.csv\n",
      "part-00002-38ebd5a2-ff1b-42a4-aa48-437af9b7ff38-c000.csv\n",
      "part-00003-38ebd5a2-ff1b-42a4-aa48-437af9b7ff38-c000.csv\n"
     ]
    }
   ],
   "source": [
    "! ls df1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "670b4320-3481-49bf-9252-391073ac7f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/04/2019 19:48:06,loc0,29\n",
      "03/04/2019 19:53:06,loc0,27\n",
      "03/04/2019 19:58:06,loc0,28\n",
      "03/04/2019 20:03:06,loc0,30\n",
      "03/04/2019 20:08:06,loc0,27\n",
      "03/04/2019 20:13:06,loc0,27\n",
      "03/04/2019 20:18:06,loc0,27\n",
      "03/04/2019 20:23:06,loc0,29\n",
      "03/04/2019 20:28:06,loc0,32\n",
      "03/04/2019 20:33:06,loc0,35\n"
     ]
    }
   ],
   "source": [
    "! head df1.csv/part-00000-38ebd5a2-ff1b-42a4-aa48-437af9b7ff38-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63684215-bfd5-4375-b592-8d292ae68937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.write.json('df1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87aa5f62-8bec-4550-8a00-079004005590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\n",
      "part-00000-f5f8eaab-3476-4ed2-962e-3865e8022d3d-c000.json\n",
      "part-00001-f5f8eaab-3476-4ed2-962e-3865e8022d3d-c000.json\n",
      "part-00002-f5f8eaab-3476-4ed2-962e-3865e8022d3d-c000.json\n",
      "part-00003-f5f8eaab-3476-4ed2-962e-3865e8022d3d-c000.json\n"
     ]
    }
   ],
   "source": [
    "! ls df1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1480afa1-534d-4419-b1e4-f3ecf8cfb583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"event_date\":\"03/04/2019 19:48:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"29\"}\n",
      "{\"event_date\":\"03/04/2019 19:53:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"27\"}\n",
      "{\"event_date\":\"03/04/2019 19:58:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"28\"}\n",
      "{\"event_date\":\"03/04/2019 20:03:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"30\"}\n",
      "{\"event_date\":\"03/04/2019 20:08:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"27\"}\n",
      "{\"event_date\":\"03/04/2019 20:13:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"27\"}\n",
      "{\"event_date\":\"03/04/2019 20:18:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"27\"}\n",
      "{\"event_date\":\"03/04/2019 20:23:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"29\"}\n",
      "{\"event_date\":\"03/04/2019 20:28:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"32\"}\n",
      "{\"event_date\":\"03/04/2019 20:33:06\",\"location_id\":\"loc0\",\"temp_celcius\":\"35\"}\n"
     ]
    }
   ],
   "source": [
    "! head df1.json/part-00000-f5f8eaab-3476-4ed2-962e-3865e8022d3d-c000.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec0c34-f8a0-47d7-85c3-e99e2fe4ccec",
   "metadata": {},
   "source": [
    "##  --- SPARK SQL ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7be23c62-a16b-47bd-9d8d-33cd09cdcaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_df1_path = data_path + '/utlization.json'\n",
    "df = spark.read.format('json').load(json_df1_path)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf0e0fe9-b7e9-423c-b1fe-7a73ab5c1e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b39d3a41-16d0-4661-a4f3-e625b6f25e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c2ca74e-282f-4491-9a6f-7ee53da63d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql('SELECT * FROM utilization LIMIT 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04b43ae9-6b08-4154-a573-8434e53e1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "569be12a-63cb-45db-82b1-77c4b530d1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      100|           47|\n",
      "|      100|           43|\n",
      "|      100|           62|\n",
      "|      100|           50|\n",
      "|      100|           43|\n",
      "|      100|           48|\n",
      "|      100|           58|\n",
      "|      100|           58|\n",
      "|      100|           62|\n",
      "|      100|           45|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, session_count FROM utilization LIMIT 10')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "279cb4f4-c61c-4a18-840d-eb7ae5a5c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|SID| SC|\n",
      "+---+---+\n",
      "|100| 47|\n",
      "|100| 43|\n",
      "|100| 62|\n",
      "|100| 50|\n",
      "|100| 43|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id AS SID, session_count AS SC FROM utilization LIMIT 10')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c57bdb4-322f-4f84-b1bb-403a76ec562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.61|03/05/2019 08:07:25|       0.15|      140|           69|\n",
      "|           0.48|03/05/2019 08:12:25|       0.36|      140|           65|\n",
      "|           0.48|03/05/2019 08:17:25|       0.36|      140|           62|\n",
      "|           0.74|03/05/2019 08:22:25|       0.31|      140|           79|\n",
      "|           0.55|03/05/2019 08:27:25|       0.51|      140|           68|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT * FROM utilization WHERE server_id = 140')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da77b0fd-7425-4d2b-b447-8a500b463eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b5c276d-f339-42ac-81fa-5950c092b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, session_count FROM utilization WHERE session_count > 70')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c662d1d7-2f5d-4724-84b5-4ba09e8d65f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239659"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bbdc2309-85c2-4855-a918-db6f8b48386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           71|\n",
      "|      120|           73|\n",
      "|      120|           72|\n",
      "|      120|           78|\n",
      "+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2733"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, session_count \\\n",
    "                    FROM utilization WHERE session_count > 70 AND server_id = 120')\n",
    "df_sql.show(5)\n",
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36802014-9a80-43d0-a044-68d477c65272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, session_count \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 AND server_id = 120 \\\n",
    "                    ORDER BY session_count DESC')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b7515-38c6-4aa4-8697-ce74cf1d65a1",
   "metadata": {},
   "source": [
    "## 2\n",
    "Operations with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6945010b-1170-4ae7-810e-88a84c23628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23d52a1e-19b2-4626-a22a-540bcc657b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e5ca485-5510-48ae-96de-540570cf88fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  500000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_count = spark.sql('SELECT count(*) FROM utilization')\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f376a93-43d1-4d74-a10b-28fa600e39c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  239659|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7657543-709e-4259-954d-7f934d5c34e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|S_ID|count(1)|\n",
      "+----+--------+\n",
      "| 103|    8744|\n",
      "| 104|    7366|\n",
      "| 100|     391|\n",
      "| 105|    1110|\n",
      "| 101|    9808|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id as S_ID, count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e65f37cb-c37c-4e9b-b300-b24ed9a88e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|S_ID|count(1)|\n",
      "+----+--------+\n",
      "| 101|    9808|\n",
      "| 113|    9418|\n",
      "| 145|    9304|\n",
      "| 103|    8744|\n",
      "| 102|    8586|\n",
      "+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id as S_ID, count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id \\\n",
    "                    ORDER BY count(*) DESC')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a82b496e-a10b-4fef-914c-8711ab4bbc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+---+\n",
      "|S_ID|min|  avg|max|\n",
      "+----+---+-----+---+\n",
      "| 101| 71|87.67|105|\n",
      "| 113| 71|86.96|103|\n",
      "| 145| 71|86.98|103|\n",
      "| 103| 71|85.76|101|\n",
      "| 102| 71|85.71|101|\n",
      "+----+---+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id as S_ID, min(session_count) AS min, \\\n",
    "                    round(avg(session_count),2) AS avg, max(session_count) AS max \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id \\\n",
    "                    ORDER BY count(*) DESC')\n",
    "df_sql.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dedd20-ac48-48e4-8f68-d1fcb2d6d744",
   "metadata": {},
   "source": [
    "## 3\n",
    "Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f5b6eb23-e7ae-4d06-8185-218a4408f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util = df\n",
    "df_util.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "06c3d8e4-e3c8-4e0e-976e-67b8dc825851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "750dcbb5-715a-4519-939d-be4b15a90848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|server_id|server_name|\n",
      "+---------+-----------+\n",
      "|      100| 100 Server|\n",
      "|      101| 101 Server|\n",
      "|      102| 102 Server|\n",
      "|      103| 103 Server|\n",
      "|      104| 104 Server|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df_path = data_path + '/server_name.csv'\n",
    "df_server = spark.read.csv(csv_df_path, header = True)\n",
    "df_server.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e938af3c-fbe6-422e-bf13-eef8bc58c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_server.createOrReplaceTempView('server_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "538d5048-ca64-4dd5-bf57-238615dad0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|server_id|\n",
      "+---------+\n",
      "|      100|\n",
      "|      101|\n",
      "|      102|\n",
      "|      103|\n",
      "|      104|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_count = spark.sql('SELECT DISTINCT server_id \\\n",
    "                      FROM utilization \\\n",
    "                      ORDER BY server_id')\n",
    "df_count.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "05aa0651-c06e-4cd4-abde-4e23330f786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|min(server_id)|max(server_id)|\n",
      "+--------------+--------------+\n",
      "|           100|           149|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT min(server_id), max(server_id) FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe024475-1856-43d6-ae59-4ee1b5b4da4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: utilization; line 1 pos 79;\n'Project ['u.server_id, 'sn.server_name, 'u.session_count]\n+- 'Join Inner, ('sn.server_id = 'u.server_id)\n   :- 'SubqueryAlias u\n   :  +- 'UnresolvedRelation [utilization], [], false\n   +- 'SubqueryAlias sn\n      +- 'UnresolvedRelation [server_name], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_join \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSELECT u.server_id, sn.server_name, u.session_count \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m                      FROM utilization AS u \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m                      INNER JOIN server_name AS sn\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m                      ON sn.server_id = u.server_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_join\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: utilization; line 1 pos 79;\n'Project ['u.server_id, 'sn.server_name, 'u.session_count]\n+- 'Join Inner, ('sn.server_id = 'u.server_id)\n   :- 'SubqueryAlias u\n   :  +- 'UnresolvedRelation [utilization], [], false\n   +- 'SubqueryAlias sn\n      +- 'UnresolvedRelation [server_name], [], false\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql('SELECT u.server_id, sn.server_name, u.session_count \\\n",
    "                      FROM utilization AS u \\\n",
    "                      INNER JOIN server_name AS sn\\\n",
    "                      ON sn.server_id = u.server_id')\n",
    "df_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf2453-b9b2-4c8a-8453-ea14243ccb9d",
   "metadata": {},
   "source": [
    "## 4\n",
    "Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3783a9c3-3f75-4b06-a8c3-24b83516ec24",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /var/folders/q3/19rgddrx3zs2lvc4fk6mgdjc0000gn/T/ipykernel_4854/2098644118.py:4 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Row\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[0;32m----> 4\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/context.py:195\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    198\u001b[0m         master,\n\u001b[1;32m    199\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         udf_profiler_cls,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/context.py:430\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    427\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    435\u001b[0m             currentAppName,\n\u001b[1;32m    436\u001b[0m             currentMaster,\n\u001b[1;32m    437\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    438\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    439\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    440\u001b[0m         )\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /var/folders/q3/19rgddrx3zs2lvc4fk6mgdjc0000gn/T/ipykernel_4854/2098644118.py:4 "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "008abadf-8362-4f1c-b408-abdefda6736d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'parallelize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_dup \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallelize\u001b[49m([Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m101 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m85\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m), \\\n\u001b[1;32m      2\u001b[0m                          Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m101 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m),\n\u001b[1;32m      3\u001b[0m                          Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m102 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m85\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m),\n\u001b[1;32m      4\u001b[0m                          Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m102 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m85\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)])\u001b[38;5;241m.\u001b[39mtoDF()\n\u001b[1;32m      5\u001b[0m df_dup\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'parallelize'"
     ]
    }
   ],
   "source": [
    "df_dup = spark.parallelize([Row(server_name='101 Server', cpu_utilization=85, session_count=80), \\\n",
    "                         Row(server_name='101 Server', cpu_utilization=80, session_count=90),\n",
    "                         Row(server_name='102 Server', cpu_utilization=85, session_count=80),\n",
    "                         Row(server_name='102 Server', cpu_utilization=85, session_count=80)]).toDF()\n",
    "df_dup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681233c-7960-4f22-8910-180d8033dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8662e18-1e1d-4dbe-aa44-2301090218c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup.drop_duplicates(['server_name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1ef16-0515-42a4-8ef6-ef12d94f4061",
   "metadata": {},
   "source": [
    "## 5\n",
    "NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cbd224-ea6b-4945-906d-bec92b15e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bfd684-0e02-4a6b-9c65-20afdb21a9ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241m.\u001b[39mparallelize([Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m101 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m85\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m), \\\n\u001b[1;32m      2\u001b[0m                              Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m101 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m),\n\u001b[1;32m      3\u001b[0m                              Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m102 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m85\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m),\n\u001b[1;32m      4\u001b[0m                              Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m103 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m70\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m),\n\u001b[1;32m      5\u001b[0m                              Row(server_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m104 Server\u001b[39m\u001b[38;5;124m'\u001b[39m, cpu_utilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, session_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)])\u001b[38;5;241m.\u001b[39mtoDF()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "df = sc.parallelize([Row(server_name='101 Server', cpu_utilization=85, session_count=80), \\\n",
    "                             Row(server_name='101 Server', cpu_utilization=80, session_count=90),\n",
    "                             Row(server_name='102 Server', cpu_utilization=85, session_count=40),\n",
    "                             Row(server_name='103 Server', cpu_utilization=70, session_count=80),\n",
    "                             Row(server_name='104 Server', cpu_utilization=60, session_count=80)]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae719f-1df8-44ad-996a-a596db1cb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150aff3-c0b5-4806-9f5f-fbb798f0dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM na_table WHERE na_col IS NULL\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894d599-3ff5-450c-a64a-9c40a93d9089",
   "metadata": {},
   "source": [
    "# ---DATA ANALYSIS---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94485180-ead7-4c64-bf0d-425874aa59cf",
   "metadata": {},
   "source": [
    "## 1\n",
    "Exploratory data analysis and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284ef05c-b6f7-40e8-bc02-ffb6b49c002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data_path = '/Users/aaron/Downloads/Ex_Files_Spark_SQL_DataFrames/Exercise Files/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab56267-c856-406a-a700-08abf91ab03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flie_path_no_header = data_path + '/utilization.csv'\n",
    "df_util = spark.read.format('csv').option('header','false').option('inferSchema','true').load(flie_path_no_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477596d1-82ea-4d7e-9888-0481728dfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util = df_util.withColumnRenamed('_c0','event_datetime') \\\n",
    "         .withColumnRenamed('_c1','server_id') \\\n",
    "         .withColumnRenamed('_c2','cpu_utilization') \\\n",
    "         .withColumnRenamed('_c3','free_memory') \\\n",
    "         .withColumnRenamed('_c4','session_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac4a7424-2ffe-499f-88c0-300c5b5cf3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb9c06d-6d80-4e73-8bb2-23747ed70963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92f6d6cd-bd87-466e-98da-827b3bac555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===========>                                              (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+-------------------+-------------------+------------------+\n",
      "|summary|     event_datetime|         server_id|    cpu_utilization|        free_memory|     session_count|\n",
      "+-------+-------------------+------------------+-------------------+-------------------+------------------+\n",
      "|  count|             500000|            500000|             500000|             500000|            500000|\n",
      "|   mean|               null|             124.5| 0.6205177400000115|0.37912809999999625|          69.59616|\n",
      "| stddev|               null|14.430884120553204|0.15875173872912818|0.15830931278376212|14.850676696352831|\n",
      "|    min|03/05/2019 08:06:14|               100|               0.22|                0.0|                32|\n",
      "|    max|04/09/2019 01:22:46|               149|                1.0|               0.78|               105|\n",
      "+-------+-------------------+------------------+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_util.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f471c7c0-fa6e-43be-b418-a49bed9ae33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.4704771573080722"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('cpu_utilization','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52eef4d4-afc0-4fe2-adaa-b68eb5fb73ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5008320848876588"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('session_count','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68a87fb6-a13c-4cea-9dad-325df6077d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+\n",
      "|session_count_freqItems| server_id_freqItems|\n",
      "+-----------------------+--------------------+\n",
      "|   [92, 101, 83, 104...|[146, 137, 101, 1...|\n",
      "+-----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.stat.freqItems(('session_count','server_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94620af8-6ea4-415e-b902-0e5fcb5a0008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149686"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df_util.sample(fraction = 0.3,withReplacement = False)\n",
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebc9e8-b303-4679-82e8-abfbd1cb806d",
   "metadata": {},
   "source": [
    "Using spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b0de928-e088-4b9f-ad5a-cf4b4b09c781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------------+\n",
      "|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "|                0.22|                 1.0|    0.15875173872912818|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8332ebb5-8f67-472b-88c4-174b68b39ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|server_id|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|      108|                0.55|                0.95|    0.11563100171171926|\n",
      "|      101|                 0.6|                 1.0|    0.11651726263197697|\n",
      "|      103|                0.56|                0.96|    0.11617507884178278|\n",
      "|      111|                0.36|                0.76|    0.11530221569464483|\n",
      "|      107|                0.45|                0.85|    0.11597417369783877|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) \\\n",
    "           FROM utilization \\\n",
    "           GROUP BY server_id').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba2184b6-10da-4b64-9b55-f6f2e4761e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|server_id|bucket|\n",
      "+---------+------+\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "22/07/26 18:20:51 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 915629 ms exceeds timeout 120000 ms\n",
      "22/07/26 18:20:51 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, FLOOR(cpu_utilization*100/10) bucket FROM utilization').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f6c28-0e10-4084-8c7a-4fc2257772fa",
   "metadata": {},
   "source": [
    "## 2\n",
    "Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b2a8fdf-54bd-4266-89b5-77db6376cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")\n",
    "df_util.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3e180e0-7e48-4f95-9565-ebb33ebfc5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|server_id|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|      108|                0.55|                0.95|    0.11563100171171926|\n",
      "|      101|                 0.6|                 1.0|    0.11651726263197697|\n",
      "|      103|                0.56|                0.96|    0.11617507884178278|\n",
      "|      111|                0.36|                0.76|    0.11530221569464483|\n",
      "|      107|                0.45|                0.85|    0.11597417369783877|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) \\\n",
    "           FROM utilization \\\n",
    "           GROUP BY server_id').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfb7a8de-e3c1-4494-b6c1-86cf73fc9d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:16|      101|           0.86|0.7985559999999872|\n",
      "|03/05/2019 08:11:16|      101|           0.71|0.7985559999999872|\n",
      "|03/05/2019 08:16:16|      101|           0.77|0.7985559999999872|\n",
      "|03/05/2019 08:21:16|      101|           0.88|0.7985559999999872|\n",
      "|03/05/2019 08:26:16|      101|           0.95|0.7985559999999872|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window = spark.sql(\"SELECT event_datetime, server_id, cpu_utilization,  \\\n",
    "         avg(cpu_utilization) OVER (PARTITION BY server_id) avg_server_util \\\n",
    "FROM  \\\n",
    "      utilization\")\n",
    "sql_window.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d42d499f-efc3-4640-b094-cb062b38944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|   delta_server_util|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|03/05/2019 08:06:16|      101|           0.86|0.7985559999999872| 0.06144400000001282|\n",
      "|03/05/2019 08:11:16|      101|           0.71|0.7985559999999872| -0.0885559999999872|\n",
      "|03/05/2019 08:16:16|      101|           0.77|0.7985559999999872|-0.02855599999998...|\n",
      "|03/05/2019 08:21:16|      101|           0.88|0.7985559999999872| 0.08144400000001284|\n",
      "|03/05/2019 08:26:16|      101|           0.95|0.7985559999999872|  0.1514440000000128|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_window2 = spark.sql(\"SELECT event_datetime, server_id, cpu_utilization,  \\\n",
    "         avg(cpu_utilization) OVER (PARTITION BY server_id) avg_server_util, \\\n",
    "         cpu_utilization - avg(cpu_utilization) OVER (PARTITION BY server_id) delta_server_util \\\n",
    "         FROM utilization\")\n",
    "sql_window2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf121091-df58-43dd-bd75-434c5fe52994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:16|      101|           0.86|0.7849999999999999|\n",
      "|03/05/2019 08:11:16|      101|           0.71|0.7799999999999999|\n",
      "|03/05/2019 08:16:16|      101|           0.77|0.7866666666666666|\n",
      "|03/05/2019 08:21:16|      101|           0.88|0.8666666666666666|\n",
      "|03/05/2019 08:26:16|      101|           0.95|0.9033333333333333|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window3 = spark.sql(\"SELECT event_datetime, server_id, cpu_utilization,  \\\n",
    "                        avg(cpu_utilization) OVER (PARTITION BY server_id ORDER BY event_datetime \\\n",
    "                        ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) avg_server_util \\\n",
    "                        FROM  \\\n",
    "                        utilization\")\n",
    "sql_window3.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57497021-064c-4f39-822c-551d28cf35a9",
   "metadata": {},
   "source": [
    "## 3\n",
    "Clustering & ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b2bfa29-000f-45c3-aa5d-15d4bae34d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")\n",
    "df_util.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfb6065b-de32-4ae6-89df-eb54fc9ddeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca65381f-b4dd-4174-9644-c3a7f59e3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=['cpu_utilization','free_memory','session_count'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de7ff00f-939e-40e8-8940-b9c8713e7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclusters_df = vectorAssembler.transform(df_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec281345-52fa-4283-8c19-487fa786fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+----------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|        features|\n",
      "+-------------------+---------+---------------+-----------+-------------+----------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|[0.57,0.51,47.0]|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|[0.47,0.62,43.0]|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|[0.56,0.57,62.0]|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|[0.57,0.56,50.0]|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|[0.35,0.46,43.0]|\n",
      "|03/05/2019 08:31:14|      100|           0.41|       0.58|           48|[0.41,0.58,48.0]|\n",
      "|03/05/2019 08:36:14|      100|           0.57|       0.35|           58|[0.57,0.35,58.0]|\n",
      "|03/05/2019 08:41:14|      100|           0.41|        0.4|           58| [0.41,0.4,58.0]|\n",
      "|03/05/2019 08:46:14|      100|           0.53|       0.35|           62|[0.53,0.35,62.0]|\n",
      "|03/05/2019 08:51:14|      100|           0.51|        0.6|           45| [0.51,0.6,45.0]|\n",
      "|03/05/2019 08:56:14|      100|           0.32|       0.37|           47|[0.32,0.37,47.0]|\n",
      "|03/05/2019 09:01:14|      100|           0.62|       0.59|           60|[0.62,0.59,60.0]|\n",
      "|03/05/2019 09:06:14|      100|           0.66|       0.72|           57|[0.66,0.72,57.0]|\n",
      "|03/05/2019 09:11:14|      100|           0.54|       0.54|           44|[0.54,0.54,44.0]|\n",
      "|03/05/2019 09:16:14|      100|           0.29|        0.4|           47| [0.29,0.4,47.0]|\n",
      "|03/05/2019 09:21:14|      100|           0.43|       0.68|           66|[0.43,0.68,66.0]|\n",
      "|03/05/2019 09:26:14|      100|           0.49|       0.66|           65|[0.49,0.66,65.0]|\n",
      "|03/05/2019 09:31:14|      100|           0.64|       0.55|           66|[0.64,0.55,66.0]|\n",
      "|03/05/2019 09:36:14|      100|           0.42|        0.6|           42| [0.42,0.6,42.0]|\n",
      "|03/05/2019 09:41:14|      100|           0.55|       0.59|           63|[0.55,0.59,63.0]|\n",
      "+-------------------+---------+---------------+-----------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vclusters_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1530a372-a5a7-4b1a-b202-b7fcece7298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ead4846-ba5a-4cdc-9b91-de28f8c827d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans.setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b328e92-0a8f-4b48-aab7-9905f18fc9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "kmodel = kmeans.fit(vclusters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e6b4c97-f939-4963-968e-a4b84e6726aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.71174897,  0.28808911, 86.87510507]),\n",
       " array([ 0.61918113,  0.38080285, 68.75004716]),\n",
       " array([ 0.51439668,  0.48445202, 50.49452021])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fce333e9-34c4-4ac5-959d-d06c7679968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8e19e13-d274-4237-bd0f-df7a1c5e6f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+--------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|features|\n",
      "+-------------------+---------+---------------+-----------+-------------+--------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|  [0.57]|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|  [0.47]|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|  [0.56]|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|  [0.57]|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|  [0.35]|\n",
      "+-------------------+---------+---------------+-----------+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"cpu_utilization\"], outputCol=\"features\")\n",
    "df_vutil = vectorAssembler.transform(df_util)\n",
    "df_vutil.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6806cc4a-df6d-4ee9-804d-fc4a634f78c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/27 10:18:28 WARN Instrumentation: [6cf19752] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/07/27 10:18:29 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/07/27 10:18:29 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/27 10:18:31 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\",labelCol=\"session_count\")\n",
    "lrModel = lr.fit(df_vutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3fe8dc4-a395-42b4-bf36-97a5a6f8c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([47.024])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dbf65ca1-dd85-4607-b323-e063209628b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.41695103553592"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9535c6da-bf2e-4318-ae2b-7da3fcd35524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.837990225931861"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.summary.rootMeanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
